{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Import basic packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import cross_validation\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('creditcard.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train['Amount_n']= StandardScaler().fit_transform(train['Amount'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9    ...          V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787    ...     0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425    ...    -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654    ...     0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024    ...     0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739    ...     0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  Amount_n  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  0.244964  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0 -0.342475  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  1.160686  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  0.140534  \n",
       "4  0.502292  0.219422  0.215153   69.99      0 -0.073403  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10    ...          V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794    ...    -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974    ...    -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643    ...     0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952    ...    -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074    ...    -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  Amount_n  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0 -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= train.drop(['Time','Amount'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X= train.ix[:, train.columns != 'Class']\n",
    "y= train.ix[:, train.columns == 'Class']\n",
    "fraud_count = len(train[train.Class == 1])\n",
    "fraud_indices = train[train.Class == 1].index\n",
    "normal_indices = train[train.Class == 0].index\n",
    "\n",
    "r_normal_indices = np.random.choice(normal_indices, fraud_count, replace = False) # random \n",
    "\n",
    "undersample_indices = np.concatenate([fraud_indices,r_normal_indices])\n",
    "undersample_train = train.iloc[undersample_indices,:]\n",
    "\n",
    "X_undersample = undersample_train.ix[:, undersample_train.columns != 'Class']\n",
    "y_undersample = undersample_train.ix[:, undersample_train.columns == 'Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "X_train_res, X_test_res, y_train_res, y_test_res= train_test_split(X_undersample,y_undersample,test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy score:0.942567567568\n",
      "[[142   7]\n",
      " [ 10 137]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       149\n",
      "          1       0.95      0.93      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train_res,y_train_res)\n",
    "testscoreLR=accuracy_score(y_test_res,lr.predict(X_test_res))\n",
    "print('logistic regression accuracy score:'+str(testscoreLR))\n",
    "print(confusion_matrix(y_test_res,lr.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,lr.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:0.908783783784\n",
      "[[138  11]\n",
      " [ 16 131]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.91       149\n",
      "          1       0.92      0.89      0.91       147\n",
      "\n",
      "avg / total       0.91      0.91      0.91       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train_res,y_train_res)\n",
    "testscoreDT=accuracy_score(y_test_res,dt.predict(X_test_res))\n",
    "print('Decision Tree accuracy score:'+str(testscoreDT))\n",
    "print(confusion_matrix(y_test_res,dt.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,dt.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:0.898648648649\n",
      "[[133  16]\n",
      " [ 14 133]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.89      0.90       149\n",
      "          1       0.89      0.90      0.90       147\n",
      "\n",
      "avg / total       0.90      0.90      0.90       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(max_depth=8)\n",
    "dt.fit(X_train_res,y_train_res)\n",
    "testscoreDT=accuracy_score(y_test_res,dt.predict(X_test_res))\n",
    "print('Decision Tree accuracy score:'+str(testscoreDT))\n",
    "print(confusion_matrix(y_test_res,dt.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,dt.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy score:0.956081081081\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_res,y_train_res)\n",
    "testscoreRF=accuracy_score(y_test_res,rf.predict(X_test_res))\n",
    "print('Random Forest accuracy score:'+str(testscoreRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146   3]\n",
      " [ 10 137]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       149\n",
      "          1       0.98      0.93      0.95       147\n",
      "\n",
      "avg / total       0.96      0.96      0.96       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_res,rf.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,rf.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:0.912162162162\n",
      "[[143   6]\n",
      " [ 20 127]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92       149\n",
      "          1       0.95      0.86      0.91       147\n",
      "\n",
      "avg / total       0.92      0.91      0.91       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gaussian navie bayers\n",
    "nb=GaussianNB()\n",
    "nb.fit(X_train_res,y_train_res)\n",
    "testscoreNB=accuracy_score(y_test_res,nb.predict(X_test_res))\n",
    "print('Decision Tree accuracy score:'+str(testscoreNB))\n",
    "print(confusion_matrix(y_test_res,nb.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,nb.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:0.939189189189\n",
      "[[145   4]\n",
      " [ 14 133]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       149\n",
      "          1       0.97      0.90      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "kn=KNeighborsClassifier()\n",
    "kn.fit(X_train_res,y_train_res)\n",
    "testscoreKN=accuracy_score(y_test_res,kn.predict(X_test_res))\n",
    "print('Decision Tree accuracy score:'+str(testscoreKN))\n",
    "print(confusion_matrix(y_test_res,kn.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,kn.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score:0.945945945946\n",
      "[[145   4]\n",
      " [ 12 135]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.95       149\n",
      "          1       0.97      0.92      0.94       147\n",
      "\n",
      "avg / total       0.95      0.95      0.95       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "gbm0.fit(X_train_res,y_train_res)\n",
    "testscoreGBM=accuracy_score(y_test_res,gbm0.predict(X_test_res))\n",
    "print('Decision Tree accuracy score:'+str(testscoreGBM))\n",
    "print(confusion_matrix(y_test_res,gbm0.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,gbm0.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy score:0.942567567568\n",
      "[[142   7]\n",
      " [ 10 137]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       149\n",
      "          1       0.95      0.93      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "sv=svm.SVC()\n",
    "sv.fit(X_train_res,y_train_res)\n",
    "testscoreSV=accuracy_score(y_test_res,sv.predict(X_test_res))\n",
    "print('SVM accuracy score:'+str(testscoreSV))\n",
    "print(confusion_matrix(y_test_res,sv.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,sv.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network accuracy score:0.932432432432\n",
      "[[139  10]\n",
      " [ 10 137]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93       149\n",
      "          1       0.93      0.93      0.93       147\n",
      "\n",
      "avg / total       0.93      0.93      0.93       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_train_res,y_train_res)\n",
    "testscoreMLP=accuracy_score(y_test_res,mlp.predict(X_test_res))\n",
    "print('Neural Network accuracy score:'+str(testscoreMLP))\n",
    "print(confusion_matrix(y_test_res,mlp.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,mlp.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Testing_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random Forest</td>\n",
       "      <td>0.956081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.955285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.942568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>0.939189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGS BOoster class.</td>\n",
       "      <td>0.932432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bays</td>\n",
       "      <td>0.912162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.898649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Testing_Score\n",
       "0        random Forest       0.956081\n",
       "2  Logistic Regression       0.955285\n",
       "7                  SVM       0.945946\n",
       "6       Neural Network       0.942568\n",
       "3       KNN Regression       0.939189\n",
       "5   XGS BOoster class.       0.932432\n",
       "4  Gaussian Naive Bays       0.912162\n",
       "1        Decision Tree       0.898649"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arrrange the model according tp there accuracy score\n",
    "models = pd.DataFrame({'Model' : [ 'random Forest', 'Decision Tree', 'Logistic Regression', 'KNN Regression','Gaussian Naive Bays','XGS BOoster class.','Neural Network','SVM'],'Testing_Score' : [ testscoreRF, testscoreDT, testscoreLR, testscoreKN, testscoreNB, testscoreMLP, testscoreSV, testscoreGBM ],})\n",
    "models.sort_values(by='Testing_Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature ranking:\n",
      "feature no. 1: V14 (0.232887584098)\n",
      "feature no. 2: V10 (0.12786424325)\n",
      "feature no. 3: V12 (0.114836459304)\n",
      "feature no. 4: V4 (0.0827822990603)\n",
      "feature no. 5: V3 (0.0632745454063)\n",
      "feature no. 6: V17 (0.0613275477213)\n",
      "feature no. 7: V11 (0.0395394287429)\n",
      "feature no. 8: V16 (0.0306014986831)\n",
      "feature no. 9: V7 (0.0305544118259)\n",
      "feature no. 10: V2 (0.0293091964018)\n",
      "feature no. 11: V9 (0.0181532981186)\n",
      "feature no. 12: V21 (0.0152188369746)\n",
      "feature no. 13: V20 (0.0133841994811)\n",
      "feature no. 14: V18 (0.0133252143128)\n",
      "feature no. 15: V19 (0.0132433561541)\n",
      "feature no. 16: V8 (0.0107008154697)\n",
      "feature no. 17: V27 (0.0101950852285)\n",
      "feature no. 18: Amount_n (0.0101463830473)\n",
      "feature no. 19: V5 (0.00992540004307)\n",
      "feature no. 20: V6 (0.00946288345181)\n",
      "feature no. 21: V13 (0.00910707687621)\n",
      "feature no. 22: V28 (0.00867636449715)\n",
      "feature no. 23: V26 (0.00825379843379)\n",
      "feature no. 24: V23 (0.00800395209798)\n",
      "feature no. 25: V1 (0.00681359159934)\n",
      "feature no. 26: V15 (0.00634406114844)\n",
      "feature no. 27: V22 (0.00609468395637)\n",
      "feature no. 28: V25 (0.00561681292948)\n",
      "feature no. 29: V24 (0.00435697168596)\n"
     ]
    }
   ],
   "source": [
    "#using Random Forest\n",
    "importances=rf.feature_importances_\n",
    "f=np.argsort(importances)[::-1]\n",
    "print ('feature ranking:')\n",
    "for i in range(X.shape[1]):\n",
    "     print (\"feature no. {}: {} ({})\".format(i+1,X.columns[f[i]],importances[f[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116508950>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature':X_tr.columns,'importance':np.round(rf.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=True).set_index('feature')\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature ranking:\n",
      "feature no. 1: V14 (0.777877221297)\n",
      "feature no. 2: V4 (0.0629156961641)\n",
      "feature no. 3: V15 (0.0202758817105)\n",
      "feature no. 4: V18 (0.019756779226)\n",
      "feature no. 5: V12 (0.017924112137)\n",
      "feature no. 6: V17 (0.0168631095414)\n",
      "feature no. 7: V6 (0.0160149649787)\n",
      "feature no. 8: V23 (0.0112766779039)\n",
      "feature no. 9: V3 (0.00798253706102)\n",
      "feature no. 10: V20 (0.00755809316223)\n",
      "feature no. 11: V7 (0.00747872044887)\n",
      "feature no. 12: V22 (0.00579501191685)\n",
      "feature no. 13: V27 (0.00555926688178)\n",
      "feature no. 14: V26 (0.00546173588386)\n",
      "feature no. 15: V9 (0.00449017709682)\n",
      "feature no. 16: V8 (0.00399126853051)\n",
      "feature no. 17: V24 (0.00399126853051)\n",
      "feature no. 18: V11 (0.00319097011717)\n",
      "feature no. 19: V25 (0.0015965074122)\n",
      "feature no. 20: V2 (0.0)\n",
      "feature no. 21: V5 (0.0)\n",
      "feature no. 22: Amount_n (0.0)\n",
      "feature no. 23: V10 (0.0)\n",
      "feature no. 24: V13 (0.0)\n",
      "feature no. 25: V28 (0.0)\n",
      "feature no. 26: V16 (0.0)\n",
      "feature no. 27: V19 (0.0)\n",
      "feature no. 28: V21 (0.0)\n",
      "feature no. 29: V1 (0.0)\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "importances=dt.feature_importances_\n",
    "f=np.argsort(importances)[::-1]\n",
    "print ('feature ranking:')\n",
    "for i in range(X.shape[1]):\n",
    "     print (\"feature no. {}: {} ({})\".format(i+1,X.columns[f[i]],importances[f[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116e92ed0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature':X_tr.columns,'importance':np.round(dt.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=True).set_index('feature')\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAFlCAYAAAByazuwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJiKTUBIiIilvr/UZp6oyD/SW0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1178737d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "deci = ensemble.RandomForestClassifier()\n",
    "deci.fit(train.iloc[:, 0:30], train.Class)\n",
    "importances = deci.feature_importances_\n",
    "sorted_idx = np.argsort(importances)\n",
    "\n",
    "padding = np.arange(30) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx], align='center')\n",
    "plt.yticks(padding, train.columns[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x117ad8cd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAETCAYAAADUAmpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZsD/B0vCr6AaECMgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117b3a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predprob_u = lr.predict_proba(X_test_res)[:, 1]  # default threshold 0.5\n",
    "\n",
    "plt.hist(y_predprob_u, bins=8)\n",
    "plt.xlabel('predicted probability of fraud')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Histogram of predicted probabilities') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V20       V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794  ...    0.251412 -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.069083 -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.524980  0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.208038 -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074  ...    0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= df.drop(['Time','Amount'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X= train.ix[:, train.columns != 'Class']\n",
    "y= train.ix[:, train.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdhankhad/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "fraud_count = len(train[train.Class == 1])\n",
    "fraud_indices = train[train.Class == 1].index\n",
    "normal_indices = train[train.Class == 0].index\n",
    "\n",
    "r_normal_indices = np.random.choice(normal_indices, fraud_count, replace = False) # random \n",
    "\n",
    "undersample_indices = np.concatenate([fraud_indices,r_normal_indices])\n",
    "undersample_train = train.iloc[undersample_indices,:]\n",
    "\n",
    "X_undersample = undersample_train.ix[:, undersample_train.columns != 'Class']\n",
    "y_undersample = undersample_train.ix[:, undersample_train.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('esampled Dataset has shape: ', (984, 28))\n",
      "('Total number of case of Real&duplicate ', 492)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE's\n",
    "kind = 'regular'\n",
    "sm = SMOTE(kind='regular')\n",
    "X_res, y_res = sm.fit_sample(X,y)\n",
    "\n",
    "print(\"esampled Dataset has shape: \", X_res.shape)\n",
    "print(\"Total number of case of Real&duplicate \", np.sum(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n",
      "('Training set volume:', 213605)\n",
      "('Test set volume:', 71202)\n",
      "('Total number of transactions: ', 284807)\n",
      "\n",
      "('Number transactions train dataset: ', 738)\n",
      "('Number transactions test dataset: ', 246)\n",
      "('Total number of transactions: ', 984)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "print(\"Training and testing split was successful.\")\n",
    "print('Training set volume:', X_train.shape[0])\n",
    "print('Test set volume:', X_test.shape[0])\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "X_train_res, X_test_res, y_train_res, y_test_res= train_test_split(X_res, y_res)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_res))\n",
    "print(\"Number transactions test dataset: \", len(X_test_res))\n",
    "print(\"Total number of transactions: \", len(X_train_res)+len(X_test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy score:0.930894308943\n",
      "[[122   6]\n",
      " [ 11 107]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.93       128\n",
      "          1       0.95      0.91      0.93       118\n",
      "\n",
      "avg / total       0.93      0.93      0.93       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train_res,y_train_res)\n",
    "testscoreLR=accuracy_score(y_test_res,lr.predict(X_test_res))\n",
    "print('logistic regression accuracy score:'+str(testscoreLR))\n",
    "print(confusion_matrix(y_test_res,lr.predict(X_test_res)))\n",
    "print(classification_report(y_test_res,lr.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
